{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOMOSPIE\n",
    "\n",
    "Migrating code to a Jupyter Notebook: converted bash shell scripts to cells that call on the subscript files.\n",
    "https://docs.python.org/2/library/subprocess.html\n",
    "\n",
    "Text from the paper.\n",
    "https://github.com/TauferLab/Src_SoilMoisture/tree/master/2018_BigData/docs/2018paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "\n",
    "The current availability of soil moisture data over large areas comes from satellite remote sensing technologies (i.e., radar-based systems), but these data have coarse resolution and often exhibit large spatial information gaps. Where data are too coarse or sparse for a given need (e.g., precision agriculture), one can leverage machine-learning techniques coupled with other sources of environmental information (e.g., topography) to generate gap-free information and at a finer spatial resolution (i.e., increased granularity). To this end, we develop a spatial inference engine consisting of modular stages for processing spatial environmental data, generating predictions with machine-learning techniques, and analyzing these predictions. We demonstrate the functionality of this approach and the effects of data processing choices via multiple prediction maps over a United States ecological region with a highly diverse soil moisture profile (i.e., the Middle Atlantic Coastal Plains). The relevance of our work derives from a pressing need to improve the spatial representation of soil moisture for applications in environmental sciences (e.g., ecological niche modeling, carbon monitoring systems, and other Earth system models) and precision agriculture (e.g., optimizing irrigation practices and other  land management decisions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We build a modular SOil MOisture SPatial Inference Engine (SOMOSPIE) for prediction of missing soil moisture information. SOMOSPIE includes three main stages, illustrated below: (1) data processing to select a region of interest, incorporate predictive factors such as topographic parameters, and reduce data redundancy for these new factors; (2) soil moisture \n",
    "prediction with three different machine learning methods (i.e.,  kNN, HYPPO, and RF); and (3) analysis and visualization of the prediction outputs.\n",
    "\n",
    "![inference-engine](../figs/inference-engine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input\n",
    "\n",
    "Make changes to the cell below, then in the \"Cell\" menu at the top, select \"Run All\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the user specify the working directory...\n",
    "START = \"../\"\n",
    "# ... the subfolder with the modular scripts...\n",
    "CODE = \"code/\"\n",
    "# ... the subfolder with the data...\n",
    "DATA = \"data/\"\n",
    "# ... the subfolder for output. \n",
    "OUTPUT = \"out/\"\n",
    "\n",
    "YEAR = 2016\n",
    "# Assuming SM_FILE below has multiple months of SM data, \n",
    "# specify the month here (1=January, ..., 12=December)\n",
    "# The generated predictions will go in a subfolder of the data folder named by this number.\n",
    "# Set to 0 if train file is already just 3-columns (lat, lon, sm).\n",
    "MONTH = 4\n",
    "\n",
    "#############################\n",
    "# Within the data folder...\n",
    "\n",
    "# ... there should be a subfolder with/for training data...\n",
    "TRAIN_DIR = f\"{YEAR}/t/\"#-100000\"\n",
    "# ... and a subfolder with/for evaluation data.\n",
    "EVAL_DIR = f\"{YEAR}/e/\"\n",
    "\n",
    "# THE FOLLOWING 3 THINGS WILL ONLY BE USED IF MAKE_T_E = 1.\n",
    "# Specify the location of the file with sm data.\n",
    "# Use an empty string or False if the train folder is already populated.\n",
    "SM_FILE = f\"{YEAR}/{YEAR}_ESA_monthly.rds\"\n",
    "# Specify location of eval coordinates needing covariates attached.\n",
    "# An empty string or False will indicate that the eval folder is already populated.\n",
    "EVAL_FILE = f\"\"#{YEAR}/{MONTH}/ground_sm_means_CONUS.csv\"\n",
    "# Specify location of the file with covariate data.\n",
    "# An empty string or False will indicate that covariates are already attached to train and eval files.\n",
    "COV_FILE = \"USA_topo.tif\"#8.5_topo.tif\"#6.2_topo.tif\"#\n",
    "\n",
    "##########################\n",
    "# If the Train and Eval files need to be generated, set MAKE_T_E = 1.\n",
    "MAKE_T_E = 0\n",
    "# If you wish to perform PCA, set USE_PCA = 1; otherwise USE_PCA = 0.\n",
    "USE_PCA = 0\n",
    "# Compute residuals from original test data? Set to 1.\n",
    "# Split off (e.g.) 25% of the original for test for validation? Set to 1.25\n",
    "# Use the EVAL_FILE as truth for validation? Set to 2.\n",
    "# Split off a fraction of \n",
    "VALIDATE = 1.25\n",
    "RAND_SEED = 0 #0 for new, random seed, to be found in log file\n",
    "# Create images?\n",
    "USE_VIS = 1\n",
    "\n",
    "# Specify the ecoregions to cut out of the sm data.\n",
    "#REG_LIST = [\"6.2.10\", \"6.2.12\", \"6.2.13\", \"6.2.14\"]\n",
    "#REG_LIST = [f\"6.2\"]#.{l3}\" for l3 in range(3, 16) if l3!=6]\n",
    "REG_LIST = [\"8.5.1\"]#, \"8.5.2\"]#, \"8.5.3\"]#\"8.5\", \n",
    "# Specify the number of km of a buffer you want on the training data.\n",
    "BUFFER = 0#100000\n",
    "\n",
    "# Dictionary with a models as keys and model-specific parameter:arglist dictionaries as values.\n",
    "MODICT = {\n",
    "#          \"1NN\":{\"-p\":[1]}, \n",
    "#          \"KKNN\":{\"-k\":[10]}, \n",
    "          \"RF\":{}, \n",
    "#          \"HYPPO\":{\"-p\":[1], \"-k\":[10], \"-D\":[3], \"-v\":[2]},\n",
    "#          \"UNMODEL\":{}\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and utility functions\n",
    "Misc. Python functions to assist all the processes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "# R: raster, caret, quantregForest, rgdalless, kknn, rasterVis\n",
    "# Python2: pandas, sklearn, argparse, sys, numpy, itertools, random, \n",
    "#          scipy, matplotlib, re, ipykernel\n",
    "# Python3: argparse, re, itertools, random, scipy, ipykernel\n",
    "\n",
    "import pathlib, proc\n",
    "from subprocess import Popen\n",
    "\n",
    "# https://docs.python.org/2/library/os.html#files-and-directories\n",
    "from os import listdir, chdir \n",
    "\n",
    "from __utils import *\n",
    "# The following are in __utils\n",
    "#def bash(*argv):\n",
    "#    call([str(arg) for arg in argv])\n",
    "#    \n",
    "#def append_to_folder(folder_path, suffix):\n",
    "#    if type(folder_path)==str:\n",
    "#        return folder_path.rstrip(\"/\") + str(suffix)\n",
    "#    else:\n",
    "#        folder = folder_path.name + str(suffix)\n",
    "#        return folder_path.parent.joinpath(folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Curating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __A_curate import curate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Generating a model; making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __B_model import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __C_analyze import analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __D_visualize import visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting folder: /home/dror/Src_SoilMoisture/SOMOSPIE\n",
      "\n",
      "Original training data in: /home/dror/Src_SoilMoisture/SOMOSPIE/data/2016/t\n",
      "Original evaluation data in: /home/dror/Src_SoilMoisture/SOMOSPIE/data/2016/e\n",
      "curate(*[PosixPath('/home/dror/Src_SoilMoisture/SOMOSPIE/out/2016'), '', '', '', ['8.5.1'], 0, PosixPath('/home/dror/Src_SoilMoisture/SOMOSPIE/data/2016/t'), 4, PosixPath('/home/dror/Src_SoilMoisture/SOMOSPIE/data/2016/e'), 0, 1.25, 0])\n",
      "Curation log file: /home/dror/Src_SoilMoisture/SOMOSPIE/out/2016/proc-log4.txt\n",
      "Curated training data in: /home/dror/Src_SoilMoisture/SOMOSPIE/data/2016/t-postproc\n",
      "Curated evaluation data in: /home/dror/Src_SoilMoisture/SOMOSPIE/data/2016/e-postproc\n",
      "model(*[0, PosixPath('/home/dror/Src_SoilMoisture/SOMOSPIE/data/2016/t-postproc'), PosixPath('/home/dror/Src_SoilMoisture/SOMOSPIE/data/2016/e-postproc'), PosixPath('/home/dror/Src_SoilMoisture/SOMOSPIE/out/2016/4'), {'RF': {}}, ''])\n",
      "analysis(*['8.5.1', PosixPath('/home/dror/Src_SoilMoisture/SOMOSPIE/out/2016/4'), PosixPath('/home/dror/Src_SoilMoisture/SOMOSPIE/data/2016/original_sm'), 1.25])\n",
      "visualize(*[PosixPath('/home/dror/Src_SoilMoisture/SOMOSPIE/out/2016/4/8.5.1'), PosixPath('/home/dror/Src_SoilMoisture/SOMOSPIE/out/2016/4/8.5.1/figures'), 1, 1.25, 1, 0])\n",
      "Opening log: /home/dror/Src_SoilMoisture/SOMOSPIE/out/2016/4/8.5.1/logs/RF.txt\n",
      "Saving image to /home/dror/Src_SoilMoisture/SOMOSPIE/out/2016/4/8.5.1/figures/predictions/RF-plot.png\n",
      "Saving image to /home/dror/Src_SoilMoisture/SOMOSPIE/out/2016/4/8.5.1/figures/residuals/RF-plot.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################################\n",
    "# Wrapper script for most of the workflow\n",
    "#\n",
    "#     Arguments:\n",
    "#         START   directory of folder containing both train and predi folder\n",
    "#                 the train folder contains regional files\n",
    "#                 the predi folder must contain regional files \n",
    "#                 with the same names as in the train folder\n",
    "\n",
    "START = pathlib.Path(START).resolve()\n",
    "print(f\"Starting folder: {START}\\n\")\n",
    "    \n",
    "# Set the working directory to the code subfolder, for running the scipts       \n",
    "chdir(pathlib.Path(START, CODE))\n",
    "\n",
    "# Change data files and folders to full paths\n",
    "DATA = START.joinpath(DATA)\n",
    "if MAKE_T_E:\n",
    "    if SM_FILE:\n",
    "        SM_FILE = DATA.joinpath(SM_FILE)\n",
    "        if not SM_FILE.exists():\n",
    "            print(f\"ERROR! Specified SM_FILE does not exist: {SM_FILE}\")\n",
    "    if COV_FILE:\n",
    "        COV_FILE = DATA.joinpath(COV_FILE)\n",
    "        if not COV_FILE.exists():\n",
    "            print(f\"ERROR! Specified COV_FILE does not exist: {COV_FILE}\")\n",
    "    if EVAL_FILE:\n",
    "        EVAL_FILE = DATA.joinpath(EVAL_FILE)\n",
    "        if not EVAL_FILE.exists():\n",
    "            print(f\"ERROR! Specified EVAL_FILE does not exist: {EVAL_FILE}\")\n",
    "else:\n",
    "    SM_FILE = \"\"\n",
    "    COV_FILE = \"\"\n",
    "    EVAL_FILE = \"\"\n",
    "TRAIN_DIR = DATA.joinpath(TRAIN_DIR)\n",
    "EVAL_DIR = DATA.joinpath(EVAL_DIR)\n",
    "OUTPUT = START.joinpath(OUTPUT).joinpath(str(YEAR))\n",
    "\n",
    "print(f\"Original training data in: {TRAIN_DIR}\")\n",
    "print(f\"Original evaluation data in: {EVAL_DIR}\")\n",
    "    \n",
    "# ... so we can suffix them at will\n",
    "MNTH_SUFX = f\"-{MONTH}\"\n",
    "\n",
    "##########################################\n",
    "# 1 Data Processing\n",
    "\n",
    "# ORIG is the sm data before any filtering, for use with analysis()\n",
    "# TRAIN is the training set after filtering and pca, if specified\n",
    "# EVAL is the evaluation set after filtering and pca, if specified\n",
    "curate_input = [OUTPUT, SM_FILE, COV_FILE, EVAL_FILE, REG_LIST, BUFFER, \n",
    "                TRAIN_DIR, MONTH, EVAL_DIR, USE_PCA, VALIDATE, RAND_SEED]\n",
    "print(f\"curate(*{curate_input})\")\n",
    "ORIG, TRAIN, EVAL = curate(*curate_input)\n",
    "\n",
    "print(f\"Curated training data in: {TRAIN}\")\n",
    "print(f\"Curated evaluation data in: {EVAL}\")\n",
    "\n",
    "if len(listdir(TRAIN)) != len(listdir(EVAL)):\n",
    "    print(listdir(TRAIN))\n",
    "    print(listdir(EVAL))\n",
    "    raise Exception(\"We've got a problem! TRAIN and EVAL should have the same contents.\")\n",
    "\n",
    "##########################################\n",
    "# 2 Modeling\n",
    "\n",
    "PRED = OUTPUT.joinpath(str(MONTH))\n",
    "NOTE = \"\"\n",
    "if BUFFER:\n",
    "    NOTE += f\"-{BUFFER}\"\n",
    "if USE_PCA:\n",
    "    NOTE += \"-PCA\"\n",
    "model_input = [0, TRAIN, EVAL, PRED, MODICT, NOTE]\n",
    "print(f\"model(*{model_input})\")\n",
    "model(*model_input)\n",
    "\n",
    "##########################################\n",
    "# 3 Analysis & Visualization\n",
    "\n",
    "for region in REG_LIST:\n",
    "    #LOGS = os.path.join(PRED, region, SUB_LOGS,\"\")\n",
    "    \n",
    "    if VALIDATE:\n",
    "        analysis_input = [region, PRED, ORIG, VALIDATE]\n",
    "        print(f\"analysis(*{analysis_input})\")\n",
    "        analysis(*analysis_input)\n",
    "    \n",
    "    if USE_VIS:\n",
    "        # Specify the input data folder and the output figures folder\n",
    "        DATS = PRED.joinpath(region)\n",
    "        OUTS = DATS.joinpath(SUB_FIGS)\n",
    "        \n",
    "        visualize_input = [DATS, OUTS, 1, VALIDATE, 1, 0]\n",
    "        print(f\"visualize(*{visualize_input})\")\n",
    "        visualize(*visualize_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
